{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c99c8f",
   "metadata": {},
   "source": [
    "### 16. Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a293de5",
   "metadata": {},
   "source": [
    "### 17. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89259f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train model with Gini criterion\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "clf_gini.fit(X_train, y_train)\n",
    "\n",
    "# Print feature importances\n",
    "print(\"Feature Importances:\", clf_gini.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e07d9",
   "metadata": {},
   "source": [
    "### 18. Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ba720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with Entropy criterion\n",
    "clf_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_entropy = clf_entropy.predict(X_test)\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "print(f\"Model Accuracy with Entropy: {accuracy_entropy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b7e9a",
   "metadata": {},
   "source": [
    "### 19. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X_h, y_h = housing.data, housing.target\n",
    "\n",
    "# Split data\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X_h, y_h, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "reg = DecisionTreeRegressor(random_state=42)\n",
    "reg.fit(X_train_h, y_train_h)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_h = reg.predict(X_test_h)\n",
    "mse = mean_squared_error(y_test_h, y_pred_h)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdbe63",
   "metadata": {},
   "source": [
    "### 20. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb71805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Export tree structure\n",
    "dot_data = export_graphviz(clf, out_file=None, feature_names=iris.feature_names, class_names=iris.target_names,\n",
    "                           filled=True, rounded=True, special_characters=True)\n",
    "\n",
    "# Render and display tree\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d575f2f",
   "metadata": {},
   "source": [
    "### 21. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc453bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with max depth = 3\n",
    "clf_depth3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf_depth3.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_depth3 = clf_depth3.predict(X_test)\n",
    "accuracy_depth3 = accuracy_score(y_test, y_pred_depth3)\n",
    "print(f\"Model Accuracy with max_depth=3: {accuracy_depth3:.2f}\")\n",
    "print(f\"Fully grown tree Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394e8b8a",
   "metadata": {},
   "source": [
    "### 22. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its accuracy with a default tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with min_samples_split=5\n",
    "clf_min_samples = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
    "clf_min_samples.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_min_samples = clf_min_samples.predict(X_test)\n",
    "accuracy_min_samples = accuracy_score(y_test, y_pred_min_samples)\n",
    "print(f\"Model Accuracy with min_samples_split=5: {accuracy_min_samples:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce3c83c",
   "metadata": {},
   "source": [
    "### 23. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its accuracy with unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train model on scaled data\n",
    "clf_scaled = DecisionTreeClassifier(random_state=42)\n",
    "clf_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_scaled = clf_scaled.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(f\"Model Accuracy with Scaled Data: {accuracy_scaled:.2f}\")\n",
    "print(f\"Model Accuracy without Scaling: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b8bbf",
   "metadata": {},
   "source": [
    "### 24. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4232b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Train model with One-vs-Rest strategy\n",
    "ovr_clf = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
    "ovr_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_ovr = ovr_clf.predict(X_test)\n",
    "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
    "print(f\"Model Accuracy with OvR: {accuracy_ovr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff604171",
   "metadata": {},
   "source": [
    "### 25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06931f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print feature importances\n",
    "print(\"Feature Importance Scores:\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de810c",
   "metadata": {},
   "source": [
    "### 26. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6eb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with max depth = 5\n",
    "reg_depth5 = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "reg_depth5.fit(X_train_h, y_train_h)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_depth5 = reg_depth5.predict(X_test_h)\n",
    "mse_depth5 = mean_squared_error(y_test_h, y_pred_depth5)\n",
    "print(f\"MSE with max_depth=5: {mse_depth5:.2f}\")\n",
    "print(f\"MSE with unrestricted depth: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7304b2",
   "metadata": {},
   "source": [
    "### 27. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and visualize its effect on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ddcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get effective alphas for pruning\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Train models with different alphas\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for alpha in ccp_alphas:\n",
    "    clf_pruned = DecisionTreeClassifier(ccp_alpha=alpha, random_state=42)\n",
    "    clf_pruned.fit(X_train, y_train)\n",
    "    \n",
    "    train_scores.append(clf_pruned.score(X_train, y_train))\n",
    "    test_scores.append(clf_pruned.score(X_test, y_test))\n",
    "\n",
    "# Plot accuracy vs alpha\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(ccp_alphas, train_scores, marker='o', label=\"Train Accuracy\")\n",
    "plt.plot(ccp_alphas, test_scores, marker='o', label=\"Test Accuracy\")\n",
    "plt.xlabel(\"CCP Alpha\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Effect of CCP Alpha on Model Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978303e",
   "metadata": {},
   "source": [
    "### 28. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8217e2",
   "metadata": {},
   "source": [
    "### 29. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88582d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5929e",
   "metadata": {},
   "source": [
    "### 30. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values for max_depth and min_samples_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c7944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}